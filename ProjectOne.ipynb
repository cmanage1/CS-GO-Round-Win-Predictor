{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YvAF4Mb77h7"
      },
      "source": [
        "# Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9R9ZxQyNJ0HO"
      },
      "source": [
        "## CSI4106 - Introduction to Artificial Intelligence\n",
        "## Project One \n",
        "\n",
        "Submitted On Behalf Of\n",
        "Aiden Stevenson Bradwell | abrad060@uottawa.ca | 300064655\n",
        "\n",
        "Chethin Manage | cman072@uottawa.ca | 300066367\n",
        "\n",
        "**Dataset Selected**\n",
        "- [CS:GO Round Winner Classification](https://www.kaggle.com/datasets/christianlillelund/csgo-round-winner-classification)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clDW58EvXJZQ"
      },
      "source": [
        "---\n",
        "\n",
        "# Background\n",
        "\n",
        "Counter Strike, Global Offensive is a first-person videogame, where two teams compete to either attack a target or to defend the target. \n",
        "\n",
        "Each game consists of two teams\n",
        "Each game consists of 30 rounds, where the first to win 16 games (or both 15 in a tie situation) wins the game.\n",
        "Each team consists of 5 players, and each player gets one life a round. \n",
        "\n",
        "The round begins with a 30 second purchase-period, where players can spend their money on different armor and weapons, to compete in the coming round. If the player survived the previous round, they keep their previous weapons and armor.\n",
        "\n",
        "This dataset was collected during a professional tournament, where all players involved are competing on a high level of play. This assists in the accuracy of our network, as we can assume that the players involved are of a similar ability. Therefore, we can assume that each round is can be predicted based on the weapons and status of the team. \n",
        "\n",
        "Using the data of team health, players alive, weapons purchased, map of play, and additional game stats we seek to predict which team will win the current round. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0W6GqUcWJRr"
      },
      "source": [
        "## Add Dataset and Joblibs into Runtime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8iHF4j8EUzCw"
      },
      "outputs": [],
      "source": [
        "! pip install kaggle\n",
        "\n",
        "%env KAGGLE_USERNAME=cmanage1\n",
        "%env KAGGLE_KEY=b4a5756ebbc30f138ad5296cf61ba80a\n",
        "\n",
        "! kaggle datasets download -d christianlillelund/csgo-round-winner-classification\n",
        "! unzip csgo-round-winner-classification.zip \n",
        "\n",
        "! git clone https://github.com/cmanage1/ProjectOne-4106.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggUTQq-4W0XM"
      },
      "source": [
        "## Clean Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tn42t2RJS8Oc"
      },
      "source": [
        "Data is using Professional Matches. Professional match rules state\n",
        "- 20 second buy times \n",
        "- 1m 55s rounds (115s)\n",
        "\n",
        "Since the data fromt he start of the round (where both teams have all players, and all weapons) would be 50/50 chances, we are only interested in predicting the winner based on the mid-game stats. This will be more representative of how the round is actaully going. \n",
        "- Filtering to snapshots only taken 60s to 120s mark so we're not considering end-round stats or buy-round factors\n",
        "\n",
        "\n",
        "Additionally, within CSGO there is consideration needed for the map being played. It is knoweldge in the playerbase that some maps provide a firm advantage to one team. We have converted this attribute to a one-hot system to be used as inputs for the Multilayer processs and naive bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KQefwfV0SgMe"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data = pd.read_csv('csgo_round_snapshots.csv')\n",
        "data.head()\n",
        "\n",
        "data = data[data['time_left'].between(60, 120.00)]\n",
        "\n",
        "# Bucket gun data\n",
        "data[\"ct_rifles\"] = data[\"ct_weapon_ak47\"] + data[\"ct_weapon_aug\"] + data[\"ct_weapon_awp\"] + data[\"ct_weapon_famas\"] + data[\"ct_weapon_g3sg1\"] + data[\"ct_weapon_famas\"] + data[\"ct_weapon_galilar\"] +  data[\"ct_weapon_m4a1s\"] + data[\"ct_weapon_m4a4\"] + data[\"ct_weapon_scar20\"] + data[\"ct_weapon_sg553\"] + data[\"ct_weapon_ssg08\"] + data[\"ct_weapon_sg553\"]\n",
        "data[\"ct_heavy\"] = data[\"ct_weapon_m249\"] + data[\"ct_weapon_mag7\"] + data[\"ct_weapon_negev\"] + data[\"ct_weapon_nova\"] + data[\"ct_weapon_sawedoff\"] + data[\"ct_weapon_xm1014\"]\n",
        "data[\"ct_smg\"] = data[\"ct_weapon_mac10\"] + data[\"ct_weapon_bizon\"] + data[\"ct_weapon_mp5sd\"] + data[\"ct_weapon_mp7\"] + data[\"ct_weapon_mp9\"] + data[\"ct_weapon_p90\"] + data[\"ct_weapon_ump45\"]\n",
        "data[\"ct_pistol\"] = data[\"ct_weapon_cz75auto\"] + data[\"ct_weapon_elite\"] + data[\"ct_weapon_glock\"] + data[\"ct_weapon_r8revolver\"] + data[\"ct_weapon_deagle\"] + data[\"ct_weapon_fiveseven\"] + data[\"ct_weapon_usps\"] + data[\"ct_weapon_p250\"] + data[\"ct_weapon_p2000\"] + data[\"ct_weapon_tec9\"]\n",
        "\n",
        "data[\"t_rifles\"] = data[\"t_weapon_ak47\"] + data[\"t_weapon_aug\"] + data[\"t_weapon_awp\"] + data[\"t_weapon_famas\"] + data[\"t_weapon_g3sg1\"] + data[\"t_weapon_famas\"] + data[\"t_weapon_galilar\"] + data[\"t_weapon_m4a1s\"] + data[\"t_weapon_m4a4\"] + data[\"t_weapon_scar20\"] + data[\"t_weapon_sg553\"] + data[\"t_weapon_ssg08\"] + data[\"t_weapon_sg553\"]\n",
        "data[\"t_heavy\"] = data[\"t_weapon_m249\"] + data[\"t_weapon_mag7\"] + data[\"t_weapon_negev\"] + data[\"t_weapon_nova\"] + data[\"t_weapon_sawedoff\"] + data[\"t_weapon_xm1014\"]\n",
        "data[\"t_smg\"] = data[\"t_weapon_mac10\"] + data[\"t_weapon_bizon\"] + data[\"t_weapon_mp5sd\"] + data[\"t_weapon_mp7\"] + data[\"t_weapon_mp9\"] + data[\"t_weapon_p90\"] + data[\"t_weapon_ump45\"]\n",
        "data[\"t_pistol\"] = data[\"t_weapon_cz75auto\"] + data[\"t_weapon_elite\"] + data[\"t_weapon_glock\"] + data[\"t_weapon_r8revolver\"] + data[\"t_weapon_deagle\"] + data[\"t_weapon_fiveseven\"] + data[\"t_weapon_usps\"] + data[\"t_weapon_p250\"] + data[\"t_weapon_p2000\"] + data[\"t_weapon_tec9\"]\n",
        "\n",
        "data[\"ct_grenades\"] = data[\"ct_grenade_hegrenade\"] + data[\"ct_grenade_flashbang\"] + data[\"ct_grenade_smokegrenade\"] + data[\"ct_grenade_incendiarygrenade\"] + data[\"ct_grenade_molotovgrenade\"] + data[\"ct_grenade_decoygrenade\"]\n",
        "data[\"t_grenades\"] = data[\"t_grenade_hegrenade\"] + data[\"t_grenade_flashbang\"] + data[\"t_grenade_smokegrenade\"] + data[\"t_grenade_incendiarygrenade\"] + data[\"t_grenade_molotovgrenade\"] + data[\"t_grenade_decoygrenade\"]\n",
        "\n",
        "y = data[\"round_winner\"]\n",
        "\n",
        "# Create labels for dataframe \n",
        "labels = [\"time_left\", \"t_score\", \"ct_score\", \n",
        "          \"bomb_planted\", \"ct_armor\", \"t_armor\", \"ct_helmets\", \n",
        "          \"t_helmets\", \"ct_defuse_kits\", \"ct_players_alive\", \n",
        "          \"t_players_alive\", \"ct_rifles\", \"ct_heavy\", \"ct_smg\", \n",
        "          \"ct_pistol\", \"ct_grenades\", \"t_rifles\", \"t_heavy\", \n",
        "          \"t_smg\", \"t_pistol\", \"t_grenades\", \"de_inferno\" ,\"de_dust2\", \n",
        "          \"de_nuke\", \"de_mirage\", \"de_overpass\"]\n",
        "\n",
        "\n",
        "# One-Hot-Conversion for training which requires numerical data opposed to string classification. \n",
        "one_hot_data = data.copy()\n",
        "one_hot_data[\"de_inferno\"] = one_hot_data[\"map\"] == \"de_inferno\"\n",
        "one_hot_data[\"de_dust2\"] = one_hot_data[\"map\"] == \"de_dust2\"\n",
        "one_hot_data[\"de_nuke\"] = one_hot_data[\"map\"] == \"de_nuke\"\n",
        "one_hot_data[\"de_mirage\"] = one_hot_data[\"map\"] == \"de_mirage\"\n",
        "one_hot_data[\"de_overpass\"] = one_hot_data[\"map\"] == \"de_overpass\"\n",
        "\n",
        "one_hot_data[\"de_inferno\"] = one_hot_data[\"de_inferno\"]*1\n",
        "one_hot_data[\"de_dust2\"] = one_hot_data[\"de_inferno\"]*1\n",
        "one_hot_data[\"de_nuke\"] = one_hot_data[\"de_nuke\"]*1\n",
        "one_hot_data[\"de_mirage\"] = one_hot_data[\"de_mirage\"]*1\n",
        "one_hot_data[\"de_overpass\"] = one_hot_data[\"de_overpass\"]*1\n",
        "\n",
        "# Label data\n",
        "one_hot_data = one_hot_data[labels]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wypnetQz8pWW"
      },
      "source": [
        "# Naive Bayes"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Version One: Gaussian Naive Bayes<br>\n",
        "  - Training / Testing Data split: 0.33\n",
        "  - var_smoothing=1e-9\n",
        "  - Accuracy: 0.6484263715832246 average over 25 k-fold scoring\n",
        "  - Percision: 0.6582439299830605\n",
        "  - Recall: 0.65372589890568\n",
        "\n",
        "Note: changing splitting variable produces minute differences in prediction accurracy, in the range of 0.02 "
      ],
      "metadata": {
        "id": "jbwqCi0FNAsI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGy44VT-J-N1",
        "outputId": "b4582453-fb1d-49c9-abcf-c5e0713d3917"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6780312884643674\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6768089739093179"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.naive_bayes import ComplementNB\n",
        "\n",
        "from sklearn.metrics import PrecisionRecallDisplay\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import precision_score\n",
        "\n",
        "X_train_naive, X_test_naive, y_train_naive, y_test_naive = train_test_split(one_hot_data, y, test_size=0.3)\n",
        "\n",
        "\n",
        "gaussian_naive_byers = GaussianNB(var_smoothing=1e-9)\n",
        "y_pred = gaussian_naive_byers.fit(X_train_naive, y_train_naive).predict(X_test_naive)\n",
        "\n",
        "scores = cross_val_score(gaussian_naive_byers, one_hot_data, y, cv=25)\n",
        "avg_score = scores.sum()/25\n",
        "print(avg_score)\n",
        "\n",
        "precision_score(y_test_naive, y_pred, average='macro')\n",
        "recall_score(y_test_naive, y_pred, average='macro')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y79AxRiKa-PZ"
      },
      "source": [
        "### Version Two: Multinomial Naive Bayes\n",
        "  - Training Data split: 0.33 \n",
        "  - ALPHA | | AVERAGE ACCURACY   |          PERCISION |         RECALL\n",
        "    - 0.2 | |  0.635572548843207 | 0.6366622165467068 | 0.6354164031630551\n",
        "    - 0.3 | |  0.635572548843207 | 0.6366622165467068 | 0.6354164031630551\n",
        "    - 0.4 | |  0.635572548843207 | 0.6366622165467068 | 0.6354164031630551\n",
        "    - 0.5 | |  0.635572548843207 | 0.6366622165467068 | 0.6354164031630551\n",
        "    - 0.6 | |  0.635572548843207 | 0.6366622165467068 | 0.6354164031630551\n",
        "    - 0.7 | |  0.635572548843207 | 0.6366622165467068 | 0.6354164031630551\n",
        "    - 0.8 | |  0.635572548843207 | 0.6366622165467068 | 0.6354164031630551\n",
        "    - 0.9 | |  0.635572548843207 | 0.6366622165467068 | 0.6354164031630551\n",
        "    - 1.0 | |  0.635572548843207 | 0.6366622165467068 | 0.6354164031630551\n",
        "\n",
        "Note: Changing the alpha does not seem to have an impact on the calculated results. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-Quh71PbBNK",
        "outputId": "c0cd3703-8ece-48ee-b280-268a7fc9e091"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.67162746 0.65866539 0.67930869 0.66586654 0.66778685 0.68987038\n",
            " 0.65914546 0.65578493 0.68362938 0.66298608 0.67450792 0.662506\n",
            " 0.67642823 0.67402784 0.63736792 0.67627281 0.65129683 0.64553314\n",
            " 0.66954851 0.67291066 0.65273775 0.64793468 0.67675312 0.66186359\n",
            " 0.6493756 ]\n",
            "0.6649494305255987\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6675594341138347"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "multinomial_naive_bayes = MultinomialNB(alpha=0.1)\n",
        "y_pred = multinomial_naive_bayes.fit(X_train_naive, y_train_naive).predict(X_test_naive)\n",
        "\n",
        "scores = cross_val_score(multinomial_naive_bayes, one_hot_data, y, cv=25)\n",
        "avg_score = scores.sum()/25\n",
        "\n",
        "print(scores)\n",
        "print(avg_score)\n",
        "\n",
        "precision_score(y_test_naive, y_pred, average='macro')\n",
        "recall_score(y_test_naive, y_pred, average='macro')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvZJbpb3bLQV"
      },
      "source": [
        "\n",
        "### Version Three: Complement naive Bayes\n",
        "  - Training Data /training data split: 0.33\n",
        "  \n",
        "  - Given (alpha, norm) -> (avg_score, percision, recall)\n",
        "    - (1.0, False) -> (0.6345664462537298, 0.6418988648090815, 0.6418988648090815)\n",
        "    - (0.5, False) -> (0.6345664462537298, 0.6418988648090815, 0.6418988648090815)\n",
        "    - (0.01, False) -> (0.6345664462537298, 0.6418988648090815, 0.6418988648090815)\n",
        "    - (1.0, True) -> (0.6165320198521584, 0.6068111455108359, 0.6068111455108359)\n",
        "    - (0.5, True) -> (0.6146747034921206, 0.6070691434468525,\t0.6070691434468525)\n",
        "    - (0.01, True) -> (0.6134370923485224, 0.6060371517027864, 0.6060371517027864)\n",
        "\n",
        "\n",
        "Note: A change in the average is detected when norm=True, however this method remains less accurate than its non-normalized compliment. Could the network be overfitting on non-normalized modes?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iD-OI2BQbLlx",
        "outputId": "8d86a353-9144-482f-ad72-6921b9db3a4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.67114738 0.65914546 0.67882861 0.66394623 0.66922708 0.68843015\n",
            " 0.65962554 0.65530485 0.6831493  0.662506   0.674988   0.66154585\n",
            " 0.67546807 0.67354777 0.6364073  0.67483189 0.65273775 0.6493756\n",
            " 0.67002882 0.67291066 0.65225744 0.64793468 0.67723343 0.66090298\n",
            " 0.64793468]\n",
            "0.6647766213199299\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6667829538461861"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "from sklearn.naive_bayes import ComplementNB\n",
        "\n",
        "complement_naive_bayes = ComplementNB(alpha=0.01, norm=False)\n",
        "y_pred = complement_naive_bayes.fit(X_train_naive, y_train_naive).predict(X_test_naive)\n",
        "\n",
        "scores = cross_val_score(complement_naive_bayes, one_hot_data, y, cv=25)\n",
        "avg_score = scores.sum()/25\n",
        "\n",
        "print(scores)\n",
        "print(avg_score)\n",
        "\n",
        "precision_score(y_test_naive, y_pred, average='macro')\n",
        "recall_score(y_test_naive, y_pred, average='macro')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtI-nLqG8CfG"
      },
      "source": [
        "# Logistic Regression\n",
        "\n",
        "[SCI-KIT Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_I7nxuzt8vsj"
      },
      "source": [
        "### Version One: Logistic Regression (LBFGS Solver) <br>\n",
        "  - Training / Testing Data split: 0.33\n",
        "  - Solver: lbfgs (Limited-memory Broyden–Fletcher–Goldfarb–Shanno Algorithm)\n",
        "  - max_iter =1000\n",
        "  - Accuracy: 0.6806017925736235 \n",
        "  - Accuracy average over 25 k-fold: 0.6794047840521296\n",
        "  - Percision: 0.6795798857368007\n",
        "  - Recall: 0.6794047840521296\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hoTT122n8jh4"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "x_train_logistic, x_test_logistic, y_train_logistic, y_test_logistic = train_test_split(one_hot_data, y, test_size=0.3)\n",
        "logistic_regr_1 = LogisticRegression(solver=\"lbfgs\", max_iter=1000)\n",
        "\n",
        "# Fitting the model to learn the relationship between x and y\n",
        "logistic_regr_1.fit(x_train_logistic, y_train_logistic)\n",
        "\n",
        "logistic_regr_1.predict(x_test_logistic)\n",
        "\n",
        "# Check accuracy of prediction once\n",
        "accuracy = logistic_regr_1.score(x_test_logistic, y_test_logistic)\n",
        "print(accuracy)\n",
        "\n",
        "# Check accuracy over 25 k-fold\n",
        "scores = cross_val_score(logistic_regr_1, one_hot_data, y, cv=25)\n",
        "avg_score = scores.sum()/25\n",
        "print(avg_score)\n",
        "\n",
        "# Check precision and recall \n",
        "print(precision_score(y_test_naive, y_pred, average='macro'))\n",
        "print(recall_score(y_test_naive, y_pred, average='macro'))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Version Two: Logistic Regression (Newton Solver)\n",
        "  - Training / Testing Data split: \n",
        "  - Solver: newton-cg (Newton's method)\n",
        "  - max_iter: 1000\n",
        "  - Accuracy: 0.6903329065300896\n",
        "  - Accuracy average over 25 k-fold: 0.6858476399451576\n",
        "  - Percision: 0.6795798857368007\n",
        "  - Recall: 0.6794047840521296\n",
        "  \n",
        "**Note:** This model yields the highest accuracy and accuracy average"
      ],
      "metadata": {
        "id": "zA7nlMbsbHd4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "x_train_logistic, x_test_logistic, y_train_logistic, y_test_logistic = train_test_split(one_hot_data, y, test_size=0.3)\n",
        "logistic_regr_2 = LogisticRegression(solver=\"newton-cg\", max_iter=1000)\n",
        "\n",
        "# Fitting the model to learn the relationship between x and y\n",
        "logistic_regr_2.fit(x_train_logistic, y_train_logistic)\n",
        "\n",
        "logistic_regr_2.predict(x_test_logistic)\n",
        "\n",
        "# Check accuracy of prediction once\n",
        "accuracy = logistic_regr_2.score(x_test_logistic, y_test_logistic)\n",
        "print(accuracy)\n",
        "\n",
        "# Check accuracy over 25 k-fold\n",
        "scores = cross_val_score(logistic_regr_2, one_hot_data, y, cv=25)\n",
        "avg_score = scores.sum()/25\n",
        "print(avg_score)\n",
        "\n",
        "# Check precision and recall \n",
        "print(precision_score(y_test_naive, y_pred, average='macro'))\n",
        "print(recall_score(y_test_naive, y_pred, average='macro'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0oQD5gIVbH_y",
        "outputId": "1c5702b5-125b-4963-8246-8ea35e9596b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6854673495518566\n",
            "0.6858476399451576\n",
            "0.6678837336821521\n",
            "0.6667829538461861\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWwgdCPxfE7c"
      },
      "source": [
        "# Multi Layer Perceptron\n",
        "\n",
        "## Version One: Default parameters\n",
        "25-fold cross verification accuracy: 0.6690220037511477\n",
        "\n",
        "[0.64954393, 0.65194431, 0.69899184, 0.64858377, 0.68795007, 0.67882861,\n",
        "\n",
        " 0.70427268, 0.65482477, 0.68987038, 0.67018723, 0.674988,   0.68218915,\n",
        "\n",
        " 0.66922708, 0.64330293, 0.66138329, 0.69980788, 0.65898175, 0.65754083,\n",
        "\n",
        " 0.65898175, 0.68443804, 0.65946206, 0.65225744, 0.6820365,  0.63976945,\n",
        "\n",
        " 0.66618636]\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        " ## Version Two: Warm start\n",
        " For this network, the warm start feature was enabled with the other parameters remaining default. \n",
        "\n",
        "25-fold cross verification accuracy: 0.6627808391705784\n",
        "\n",
        "\n",
        "[0.66442631, 0.69131061, 0.62457993, 0.64378301, 0.69899184, 0.63850216,\n",
        "\n",
        " 0.63610178, 0.67594815, 0.69131061, 0.63322132, 0.65338454, 0.68074892,\n",
        "\n",
        " 0.668747,   0.656265,   0.66522574, 0.6820365,  0.65177714, 0.67002882,\n",
        "\n",
        " 0.6426513,  0.6685879,  0.67291066, 0.64121037, 0.68443804, 0.6753122,\n",
        "\n",
        " 0.65802113]\n",
        "\n",
        "\n",
        "\n",
        "--- \n",
        "\n",
        "\n",
        " ## Version Three: Small Hidden Layers\n",
        " For this network, the size of the hidden layers is reduced to 40 from the default 100. \n",
        "\n",
        "25-fold cross verification accuracy: 0.6730363590162898\n",
        "\n",
        "[0.65050408, 0.65914546, 0.69755161, 0.66826692, 0.65914546, 0.67066731,\n",
        "\n",
        " 0.67546807, 0.66490639, 0.69707153, 0.64906385, 0.70475276, 0.69803169,\n",
        "\n",
        " 0.69323092, 0.66970715, 0.66666667, 0.6753122,  0.67675312, 0.66474544,\n",
        "\n",
        " 0.69884726, 0.67867435, 0.6493756,  0.68876081, 0.68731988, 0.63928915,\n",
        "\n",
        " 0.6426513 ]\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## Version Four: Warm Start & Small Hidden Layers\n",
        " For this network, the size of the hidden layers is reduced to 40 from the default 100. Additionally, warm start is also applied\n",
        "\n",
        "25-fold cross verification accuracy: 0.6791252179599456\n",
        "\n",
        "[0.66442631, 0.69467115, 0.66298608, 0.66922708, 0.6831493,  0.70283245,\n",
        "\n",
        " 0.71531445, 0.66298608, 0.66490639, 0.67882861, 0.68843015, 0.69227076,\n",
        "\n",
        " 0.67786846, 0.67450792, 0.67002882, 0.6882805,  0.67098943, 0.65754083,\n",
        "\n",
        " 0.68780019, 0.69692603, 0.69068204, 0.68491835, 0.65946206, 0.66762728,\n",
        "\n",
        " 0.67146974]\n",
        "0.\n",
        "\n",
        " ---\n",
        "\n",
        " ## Version Five: sgd solver\n",
        "For this network, default parameters were restored with the solver being set to sgd (stochastic gradient descent)\n",
        "25-fold cross verification accuracy: 0.6802963840208669\n",
        "\n",
        "[0.65674508, 0.7018723,  0.7018723,  0.66346615, 0.69419107, 0.68602976,\n",
        "\n",
        " 0.69035046, 0.66442631, 0.68698992, 0.68506961, 0.69323092, 0.68602976,\n",
        "\n",
        " 0.68362938, 0.67930869, 0.6556196,  0.69740634, 0.66618636, 0.65850144,\n",
        "\n",
        " 0.68683958, 0.68491835, 0.68731988, 0.67339097, 0.70509126, 0.66042267,\n",
        "\n",
        " 0.65850144]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4rWe7Roerup",
        "outputId": "016e0301-316b-4860-9da2-bab14b78d061"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.65962554 0.68843015 0.67690831 0.64330293 0.63370139 0.69755161\n",
            " 0.64618339 0.67642823 0.6831493  0.67834854 0.69275084 0.68410946\n",
            " 0.69995199 0.66538646 0.67243036 0.68491835 0.67771374 0.66762728\n",
            " 0.69692603 0.69020173 0.68924111 0.66714697 0.6556196  0.66330451\n",
            " 0.67002882]\n",
            "0.6744394653576848\n"
          ]
        }
      ],
      "source": [
        "from joblib import dump, load\n",
        "\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, y, test_size=0.33)\n",
        "X_train_naive, X_test_naive, y_train_naive, y_test_naive = train_test_split(one_hot_data, y, test_size=0.3)\n",
        "\n",
        "clf = MLPClassifier( \n",
        "                    max_iter=200,\n",
        "                    hidden_layer_sizes=40,\n",
        "                    activation='relu',\n",
        "                    solver='adam',\n",
        "                    alpha=0.0001,\n",
        "                    batch_size='auto',\n",
        "                    learning_rate='constant',\n",
        "                    learning_rate_init=0.001,\n",
        "                    power_t=0.5,\n",
        "                    shuffle=True,\n",
        "                    random_state=None,\n",
        "                    tol=1e-4,\n",
        "                    verbose=False,\n",
        "                    warm_start=True,\n",
        "                    momentum=0.9,\n",
        "                    early_stopping=False,\n",
        "                    validation_fraction=0.1,\n",
        "                    beta_1=0.9,\n",
        "                    beta_2=0.999,\n",
        "                    epsilon=1e-8,\n",
        "                    n_iter_no_change=10,\n",
        "                    max_fun=15000)\n",
        "\n",
        "clf.fit(X_train_naive.values, y_train_naive)\n",
        "dump(clf, 'network_four_warm_start_small_hidden.joblib') \n",
        "\n",
        "clf.predict(X_test_naive.values)\n",
        "\n",
        "# Classifier is used for classification \n",
        "scores = cross_val_score(clf, one_hot_data.values, y, cv=25)\n",
        "avg_score = scores.sum()/25\n",
        "\n",
        "print(scores)\n",
        "print(avg_score)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dGe6QVGfznq"
      },
      "source": [
        "# Cross validation testing on the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uvDfsN2QgGYE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19532bb0-35a8-4407-a0b2-196c085f3c16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Default network || Accuracy Scores for Cross val (25 k-fold)\n",
            "0.6702311977985641\n",
            "Warm Start network || Accuracy Scores for Cross val (25 k-fold)\n",
            "0.6720381589584592\n",
            "Hidden Layer Small network || Accuracy Scores for Cross val (25 k-fold)\n",
            "0.676954588238441\n",
            "Warm start, small hidden layers network || Accuracy Scores for Cross val (25 k-fold)\n",
            "0.6792217498315581\n",
            "lbfgs network || Accuracy Scores for Cross val (25 k-fold)\n",
            "0.6790861661785195\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from joblib import dump, load\n",
        "\n",
        "# Already tested once within the model sections\n",
        "# Testing here will be the second testing with modified params \n",
        "\n",
        "default_network = load('ProjectOne-4106/network_one_default.joblib') \n",
        "warm_start_network = load('ProjectOne-4106/network_two_warm_start.joblib') \n",
        "warm_start_small_hidden_layer_network = load('ProjectOne-4106/network_four_warm_start_small_hidden.joblib') \n",
        "small_hidden_layers_network = load('ProjectOne-4106/network_three_small_hidden_layers.joblib') \n",
        "lbfgs_network = load('ProjectOne-4106/network_five_sgd.joblib') \n",
        "\n",
        "\n",
        "scores = cross_val_score(default_network, one_hot_data.values, y, cv=25)\n",
        "avg_score = scores.sum()/25\n",
        "print(\"Default network || Accuracy Scores for Cross val (25 k-fold)\")\n",
        "print(avg_score)\n",
        "\n",
        "scores = cross_val_score(warm_start_network, one_hot_data.values, y, cv=25)\n",
        "avg_score = scores.sum()/25\n",
        "print(\"Warm Start network || Accuracy Scores for Cross val (25 k-fold)\")\n",
        "print(avg_score)\n",
        "\n",
        "scores = cross_val_score(small_hidden_layers_network, one_hot_data.values, y, cv=25)\n",
        "avg_score = scores.sum()/25\n",
        "print(\"Hidden Layer Small network || Accuracy Scores for Cross val (25 k-fold)\")\n",
        "print(avg_score)\n",
        "\n",
        "scores = cross_val_score(warm_start_small_hidden_layer_network, one_hot_data.values, y, cv=25)\n",
        "avg_score = scores.sum()/25\n",
        "print(\"Warm start, small hidden layers network || Accuracy Scores for Cross val (25 k-fold)\")\n",
        "print(avg_score)\n",
        "\n",
        "scores = cross_val_score(lbfgs_network, one_hot_data.values, y, cv=25)\n",
        "avg_score = scores.sum()/25\n",
        "print(\"lbfgs network || Accuracy Scores for Cross val (25 k-fold)\")\n",
        "print(avg_score)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}